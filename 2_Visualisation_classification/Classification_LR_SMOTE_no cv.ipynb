{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "### Import the LogisticRegression and other necessary Classes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0     type                                    content_cleaned  \\\n",
      "0              1  article  speaker robin vos r rochester senate majority ...   \n",
      "1             14  article                                       page looking   \n",
      "2             15  article  contrary narrative pushed mainstream covid 19 ...   \n",
      "3             24  article  programming alert exclusive documentary origin...   \n",
      "4             30  article  buffalo ny wivbmayor byron brown handing mask ...   \n",
      "...          ...      ...                                                ...   \n",
      "1742        1573  article  rush transcript week george stephanopoulos air...   \n",
      "1743        1576  article  unprecedented moment american history need unp...   \n",
      "1744        1578  article  gov greg abbott tuesday issued amount statewid...   \n",
      "1745        1586  article  pulled trajectory chart work new version added...   \n",
      "1746        1588  article  fox business lou dobbs relentlessly grilled tr...   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "1742      0  \n",
      "1743      0  \n",
      "1744      0  \n",
      "1745      0  \n",
      "1746      0  \n",
      "\n",
      "[1747 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('all.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1397\n",
       "1     350\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the target label to see if it is an imbalanced dataset\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create training & test set\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df['content_cleaned'], df['label'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create TfidfVectorizer. Fit and transform.\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "# learn the 'vocabulary' of the training data & transform training data into a 'document-term matrix'\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "# learn the 'vocabulary' of the test data & transform test data into a 'document-term matrix'\n",
    "X_test = vectorizer.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a logistic regression model\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# train the model using X_train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for X_test\n",
    "predictions = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       278\n",
      "           1       1.00      0.40      0.57        72\n",
      "\n",
      "    accuracy                           0.88       350\n",
      "   macro avg       0.93      0.70      0.75       350\n",
      "weighted avg       0.89      0.88      0.86       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model performance before adjusting for imbalanced dataset\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8771428571428571\n",
      "Precision: 1.0\n",
      "Recall: 0.4027777777777778\n",
      "F1: 0.5742574257425743\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print('Precision:', precision_score(y_test, predictions))\n",
    "print('Recall:', recall_score(y_test, predictions))\n",
    "print('F1:', f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 278\n",
      "Before OverSampling, counts of label '0': 1119 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imblearn (if you don't have imblearn in your system) \n",
    "#pip install imblearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import SMOTE module from imblearn library \n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (2238, 7950)\n",
      "After OverSampling, the shape of train_y: (2238,) \n",
      "\n",
      "After OverSampling, counts of label '1': 1119\n",
      "After OverSampling, counts of label '0': 1119\n"
     ]
    }
   ],
   "source": [
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       278\n",
      "           1       0.96      0.76      0.85        72\n",
      "\n",
      "    accuracy                           0.95       350\n",
      "   macro avg       0.95      0.88      0.91       350\n",
      "weighted avg       0.95      0.95      0.94       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model performance after adjusting for imbalanced dataset\n",
    "\n",
    "classifier1 = LogisticRegression() \n",
    "classifier1.fit(X_train_res, y_train_res) \n",
    "predictions1 = classifier1.predict(X_test) \n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(y_test, predictions1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9457142857142857\n",
      "Precision: 0.9649122807017544\n",
      "Recall: 0.7638888888888888\n",
      "f1: 0.8527131782945737\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(y_test, predictions1))\n",
    "print('Precision:', precision_score(y_test, predictions1))\n",
    "print('Recall:', recall_score(y_test, predictions1))\n",
    "print('f1:', f1_score(y_test, predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
